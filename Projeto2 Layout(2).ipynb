{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Importando Bibliotecas: #####\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "##### Definindo as variáveis: #####\n",
    "\n",
    "    #Nome das Colunas dos Dataframes:\n",
    "n_WiA, p_WcA, n_WiB, p_WcB, p_AcT, p_BcT  = 'n(Wk∩A)', 'p(Wk|A)', 'n(Wk∩B)', 'p(Wk|B)', 'p(A|T)', 'p(B|T)'\n",
    "    #Sendo:\n",
    "        # n_WiA = n(Wk∩A) e n_WiB = n(Wk∩B)\n",
    "        # p_WcA = P(W|A) e p_WcB = P(W|B)\n",
    "\n",
    "    #Nome das categorias de tipos de emails:\n",
    "nomeA, nomeB = 'ham','spam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Símbolos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"simb.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# Ciência dos Dados - PROJETO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Nomes:  Gabriel Couto, Gabriel Miras e Mariana Abrantes\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução:\n",
    "\n",
    "### Para criar o classificador:<br>\n",
    "__1) Limpamos os emails da seguinte forma:__ <br>\n",
    "* Convertemos todos os caracteres pra minúsculos<br>\n",
    "* Trocamos todos caracteres que não são letras do alfabeto americano por espaços<br>\n",
    "* Removemos todas palavras com menos de 2 caracteres de comprimento <br>\n",
    "* Removemos os espaços excedentes<br>\n",
    "\n",
    "Outras transformações que poderiam ser feitas:<br>\n",
    "* Tirar preposições e artigos dos emails <br>\n",
    "* Considerar palavras de mesmo significado e sufixos diferentes como as mesmas (Ex: election, elections, elected)<br>\n",
    "<br>\n",
    "\n",
    "__2) Separamos os dados em 2 novos dataframes:__ <br>\n",
    "* Treinamento: Com 75% dos emails do dataframe original, será usado para gerar a tabela de frequências de palavras <br>\n",
    "* Teste: Com 25% dos emails do dataframe original, será usado no classificador para calcular se o email é spam ou não<br>\n",
    "<br>\n",
    "\n",
    "__3) Criamos uma tabela de frequência de palavras associada à sua probabilidade de ser Spam ou não__<br>\n",
    "a) Calculamos p(A) e P(B):\n",
    "$$p(A) = \\frac{n(A)}{totalEmails} \\:\\:\\:\\:\\: \\: p(B) = \\frac{n(B)}{totalEmails}$$\n",
    "\n",
    "b) Considerando a probabilidade de cada palavra como eventos independentes, sendo T o texto do email com m palavras (W1,W2,...,Wm): $$ p(T) = p(W_1)\\times p(W_2) \\times \\dots \\times p(W_m) \\: \\Longrightarrow p(T|A) \\: = p(W_1|A) \\times p(W_2|A) \\times \\dots \\times p(W_m|A) $$<br>\n",
    "\n",
    "Não podemos ter nenhuma palavra com p(Wk|A) igual a zero para não zerar p(T|A), para isso usamos Laplace Smoothing. <br>\n",
    "Fazemos isso adicionando 1 ao numerador de p(Wk|A) e palavrasD no denominador:\n",
    "$$ p(W_k|A) = \\dfrac{n(W_k∩A)}{palavrasA} \\longrightarrow p(W_k|A) = \\dfrac{n(W_k∩A)+1}{palavrasA+palavrasD}$$\n",
    "Analogamente, para B: $$ p(W_k|B) = \\dfrac{n(W_k∩B)+1}{palavrasB+palavrasD}$$\n",
    "\n",
    "Criamos uma tabela com as palavras do treinamento como índices e as colunas: p(Wk|A) e p(Wk|B) <br>\n",
    "<br> \n",
    "\n",
    "__4) Criamos o classificador Naive-Bayes para através da tabela de frequências gerada classificar o email como spam ou não__<br>\n",
    "Do teorema de Bayes: \n",
    "$$p(A|T)\\times p(T) = p(T|A)\\times p(A) \\Longrightarrow P(A|T) =  p(W_1|A) \\times \\dots \\times p(W_m|A) \\times \\dfrac{p(A)}{p(T)} $$\n",
    "Analogamente, o mesmo vale para B, basta trocar A por B na equação acima<br>\n",
    "\n",
    "As palavras que não estiverem na tabela de frequências tem p(W|A) e p(W|B) = 1/palavrasD<br>\n",
    "\n",
    "Como vamos comparar p(A|T) e p(B|T) podemos simplificar dividindo os dois lados da equação por p(T) e poderemos usar as relações: $$P(A|T) =  p(A) \\times p(W_1|A) \\times \\dots \\times p(W_m|A) $$\n",
    "$$P(B|T) =  p(B) \\times p(W_1|B) \\times \\dots \\times p(W_m|B) $$ <br>\n",
    "Se p(A|T) > p(B|T) o email é do tipo A <br>\n",
    "Se p(A|T) < p(B|T) o email é do tipo B <br>\n",
    "\n",
    "\n",
    "### Para analizar o classificador:\n",
    "__1) Alterando a base de treinamento:__<br>\n",
    "Existem várias combinações de emails possíveis de modo a obter uma amostra de treinamento com 75% dos emails do dataframe.\n",
    "Por isso, para observar como o valor dos percentuais de acerto variam com a amostra escolhida realizamos o procedimento 10 mil vezes para amostras ao acaso e salvamos os resultados obtidos numa lista.<br>\n",
    "\n",
    "__2) Do histograma no final da página:__<br>\n",
    "Temos que o histograma da taxa de acerto do classificador possui uma distribuição semelhante a uma distribuição normal, variando aproximadamente de 93 até 98, com média aproximada 95 e desvio padrão 0.49. Como o desvio padrão é pequeno comparado à taxa de acerto, o classificador mostrou-se confiável na maioria dos casos com uma só amostra. Contudo, podemos tornar o resultado ainda mais confiável e minimizar erros dividindo a base de dados em treinamento e teste mais de uma vez.\n",
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 1. Problema\n",
    "\n",
    "O Classificador Naive-Bayes, o qual se baseia no uso do teorema de Bayes, é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser SPAM considerando as palavras em seu conteúdo e, de forma complementar, permite calcular a probabilidade de uma mensagem ser HAM dada as palavras descritas na mensagem.\n",
    "\n",
    "Para realizar o MVP (minimum viable product) do projeto, você precisa programar uma versão do classificador que \"aprende\" o que é uma mensagem SPAM considerando uma base de treinamento e comparar o desempenho dos resultados com uma base de testes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Separação da base de dados em Treinamento e Teste\n",
    "\n",
    "A base de dados deve ser separada em duas partes, aleatoriamente, considerando: \n",
    "    \n",
    "    75% dos dados para a parte Treinamento; e 25% dos dados para a parte Teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregar dados:\n",
    "leitura = pd.ExcelFile('spamham2019(1).xlsx')\n",
    "dados = pd.read_excel(leitura)\n",
    "\n",
    "percentTreino = 0.75 #Proporção entre o comprimento do treinamento o dataframe dados.\n",
    "\n",
    "#SEPARAR EM TREINO E TESTE\n",
    "treinoOrig = dados.sample(frac=percentTreino,random_state=randint(0,100000))\n",
    "testeOrig = dados.drop(treinoOrig.index)\n",
    "\n",
    "#Cria índices numéricos pros dataframes\n",
    "treinoOrig.index, testeOrig.index = range(len(treinoOrig)),range(len(testeOrig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Limpando a base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Para usar o mesmo filtro para diferentes dataframes a função limparDados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limparDados(df):   \n",
    "    #Cria uma cópia do dataframe pra não adulterar os originais\n",
    "    dfLimpo = df.copy(deep=True)\n",
    "    \n",
    "    #Pega cada linha de df:\n",
    "    for numLinha in range(len(dfLimpo)):\n",
    "        linha = dfLimpo.loc[numLinha,'Email'].lower() #Linha com tudo em minúsculo\n",
    "        \n",
    "        #Subtitui caracteres que não forem letras ou espaços por espaços:\n",
    "        linhaL = re.sub(r\"[^a-z ]\",' ',linha)\n",
    "        \n",
    "        palavrasFiltradas=[]\n",
    "        #Para cada palavra da linha de df:\n",
    "        for palavra in linhaL.split(' '):\n",
    "            palavraLimpa = re.sub(r\"[^a-z]\",'',palavra)\n",
    "            \n",
    "            #Se a palavra tiver mais que 1 caractere:\n",
    "            if len(palavraLimpa) > 1:\n",
    "                palavrasFiltradas.append(palavraLimpa)\n",
    "\n",
    "        #Transformando em linha de novo\n",
    "        linhaLimpa = \" \".join(palavrasFiltradas)\n",
    "        dfLimpo.loc[numLinha,'Email'] = linhaLimpa\n",
    "    return(dfLimpo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Criar tabela de frequências de cada palavra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregar dados:\n",
    "leitura = pd.ExcelFile('spamham2019(1).xlsx')\n",
    "dados = pd.read_excel(leitura)\n",
    "dadosL = limparDados(dados)\n",
    "teste, treino = limparDados(testeOrig), limparDados(treinoOrig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n(Wk∩A)</th>\n",
       "      <th>n(Wk∩B)</th>\n",
       "      <th>p(Wk|A)</th>\n",
       "      <th>p(Wk|B)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ok</th>\n",
       "      <td>214.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.004103</td>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lar</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>double</th>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>check</th>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wif</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>da</th>\n",
       "      <td>118.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hair</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dresser</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>already</th>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         n(Wk∩A)  n(Wk∩B)   p(Wk|A)   p(Wk|B)\n",
       "ok         214.0      4.0  0.004103  0.000262\n",
       "lar         32.0      0.0  0.000630  0.000052\n",
       "double       5.0     13.0  0.000115  0.000732\n",
       "check       29.0      3.0  0.000573  0.000209\n",
       "wif         19.0      0.0  0.000382  0.000052\n",
       "da         118.0      1.0  0.002271  0.000105\n",
       "hair        17.0      0.0  0.000344  0.000052\n",
       "dresser      2.0      0.0  0.000057  0.000052\n",
       "already     70.0      1.0  0.001355  0.000105\n",
       "he         175.0      0.0  0.003359  0.000052"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = {} #Tabela de frequências \n",
    "pA,pB = (len(dados[dados.Class==nomeA]))/(len(dados)),(len(dados[dados.Class==nomeB]))/(len(dados))\n",
    "\n",
    "for numLinha in range(len(treino.Email)): \n",
    "    for palavra in treino.loc[numLinha,'Email'].split(' '):\n",
    "        if palavra not in freq:\n",
    "            freq[palavra] = {n_WiA:0, n_WiB:0, p_WcA:0,p_WcB:0}\n",
    "        if treino.loc[numLinha,'Class'] == nomeA:\n",
    "            freq[palavra][n_WiA] +=1\n",
    "        else:\n",
    "            freq[palavra][n_WiB] +=1\n",
    "\n",
    "palavrasA, palavrasB, palavrasD = 0, 0, len(freq)\n",
    "for key,valor in freq.items():  \n",
    "    palavrasA += valor[n_WiA]\n",
    "    palavrasB += valor[n_WiB]\n",
    "\n",
    "for palavra,valor in freq.items():  \n",
    "    freq[palavra][p_WcA] = (valor[n_WiA]+1)/(palavrasA+palavrasD) #Laplace Smoothing\n",
    "    freq[palavra][p_WcB] = (valor[n_WiB]+1)/(palavrasB+palavrasD) #Laplace Smoothing\n",
    "        \n",
    "# Transformando a tabela num dataframe:\n",
    "tabelapalavras = pd.DataFrame(freq).T\n",
    "tabelapalavras.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PalavrasA: 45833 | PalavrasB: 12551 | PalavrasD: 6567\n",
      "p(A): 0.8659368 | p(B): 0.13406\n"
     ]
    }
   ],
   "source": [
    "print('PalavrasA:',palavrasA,'| PalavrasB:',palavrasB, '| PalavrasD:',len(freq))\n",
    "print('p(A):',round(pA,7),'| p(B):',round(pB,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. Classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classe calculada</th>\n",
       "      <th>Classe original</th>\n",
       "      <th>Email Filtrado</th>\n",
       "      <th>Email original</th>\n",
       "      <th>p(A|T)</th>\n",
       "      <th>p(B|T)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>gonna be home soon and don want to talk about ...</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "      <td>3.32347e-53</td>\n",
       "      <td>1.20913e-62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>have date on sunday with will</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>2.37507e-17</td>\n",
       "      <td>9.70022e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>fine if that the way feel that the way its gota</td>\n",
       "      <td>Fine if thatåÕs the way u feel. ThatåÕs the wa...</td>\n",
       "      <td>5.05452e-30</td>\n",
       "      <td>1.82017e-39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>going to try for months ha ha only joking</td>\n",
       "      <td>I‰Û÷m going to try for 2 months ha ha only joking</td>\n",
       "      <td>2.59569e-28</td>\n",
       "      <td>3.47857e-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>lol your always so convincing</td>\n",
       "      <td>Lol your always so convincing.</td>\n",
       "      <td>5.51899e-16</td>\n",
       "      <td>2.42515e-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classe calculada Classe original  \\\n",
       "0              ham             ham   \n",
       "1              ham             ham   \n",
       "2              ham             ham   \n",
       "3              ham             ham   \n",
       "4              ham             ham   \n",
       "\n",
       "                                      Email Filtrado  \\\n",
       "0  gonna be home soon and don want to talk about ...   \n",
       "1                      have date on sunday with will   \n",
       "2    fine if that the way feel that the way its gota   \n",
       "3          going to try for months ha ha only joking   \n",
       "4                      lol your always so convincing   \n",
       "\n",
       "                                      Email original       p(A|T)       p(B|T)  \n",
       "0  I'm gonna be home soon and i don't want to tal...  3.32347e-53  1.20913e-62  \n",
       "1                I HAVE A DATE ON SUNDAY WITH WILL!!  2.37507e-17  9.70022e-19  \n",
       "2  Fine if thatåÕs the way u feel. ThatåÕs the wa...  5.05452e-30  1.82017e-39  \n",
       "3  I‰Û÷m going to try for 2 months ha ha only joking  2.59569e-28  3.47857e-31  \n",
       "4                     Lol your always so convincing.  5.51899e-16  2.42515e-19  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensagens={}\n",
    "\n",
    "for numLinha in range(len(teste.Email)):   \n",
    "    mensagens[numLinha] = {'Email original':testeOrig.loc[numLinha,'Email'],'Email Filtrado':teste.loc[numLinha,'Email'],\n",
    "                           'Classe original':testeOrig.loc[numLinha,'Class'],p_AcT:0,p_BcT:0}\n",
    "    \n",
    "    pAcT,pBcT=1,1\n",
    "    for palavra in teste.loc[numLinha,'Email'].split(' '):    \n",
    "        if palavra in tabelapalavras.index:\n",
    "            pAcT*= tabelapalavras.loc[palavra,p_WcA]\n",
    "            pBcT*= tabelapalavras.loc[palavra,p_WcB]\n",
    "        else:\n",
    "            pAcT*= 1/(palavrasA +len(freq))\n",
    "            pBcT*= 1/(palavrasB + len(freq))\n",
    "    \n",
    "        mensagens[numLinha][p_AcT] = pAcT*pA\n",
    "        mensagens[numLinha][p_BcT] = pBcT*pB\n",
    "\n",
    "    if pAcT >= pBcT:\n",
    "        mensagens[numLinha]['Classe calculada'] = nomeA\n",
    "    if pAcT < pBcT: \n",
    "        mensagens[numLinha]['Classe calculada'] = nomeB\n",
    "\n",
    "#Para melhorar a visualização dos emails colocamos ela num dataframe:\n",
    "tabelaEmails = pd.DataFrame(mensagens).T\n",
    "\n",
    "tabelaEmails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positivos Verdadeiros (Verdadeiros Spam):  143\n",
      "Negativos Verdadeiros (Verdadeiros Ham):  1196\n",
      "Falsos Positivos (Ham calculados como Spam): 45\n",
      "Falsos Negativos (Spam calculados como Ham):  9\n",
      "\n",
      "Precisão de acertos: 96.123 %\n"
     ]
    }
   ],
   "source": [
    "VerHam, VerSpam, FalHam, FalSpam = 0,0,0,0\n",
    "for numLinha in range(len(mensagens)):\n",
    "    #Negativo Verdadeiro\n",
    "    if (tabelaEmails.loc[numLinha,'Classe original'] == nomeA)&(tabelaEmails.loc[numLinha,'Classe calculada'] == nomeA): \n",
    "        VerHam+=1\n",
    "    #Positivos Verdadeiros\n",
    "    if (tabelaEmails.loc[numLinha,'Classe original'] == nomeB)&(tabelaEmails.loc[numLinha,'Classe calculada'] == nomeB):\n",
    "        VerSpam+=1\n",
    "    #Falso Negativo\n",
    "    if (tabelaEmails.loc[numLinha,'Classe original'] == nomeB)&(tabelaEmails.loc[numLinha,'Classe calculada'] == nomeA): \n",
    "        FalHam+=1\n",
    "    #Falsos Positivos\n",
    "    if (tabelaEmails.loc[numLinha,'Classe original'] == nomeA)&(tabelaEmails.loc[numLinha,'Classe calculada'] == nomeB): \n",
    "        FalSpam+=1\n",
    "\n",
    "#Positivo = ham | Negativo = spam \n",
    "print('Positivos Verdadeiros (Verdadeiros Spam): ',VerSpam)\n",
    "print('Negativos Verdadeiros (Verdadeiros Ham): ',VerHam)\n",
    "print('Falsos Positivos (Ham calculados como Spam):',FalSpam)\n",
    "print('Falsos Negativos (Spam calculados como Ham): ',FalHam)\n",
    "print()\n",
    "print('Precisão de acertos:',round(100*(VerSpam+VerHam)/(VerHam+VerSpam+FalHam+FalSpam),3),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Qualidade do Classificador alterando a base de treinamento\n",
    "Para fazermos o loop simplificamos o código ao máximo para reduzir o tempo de cada iteração:\n",
    "Fazendo algumas mudanças e preferencialmente trabalhando com dicionário em vez de dataframe fazemos o tempo de cada iteração cair de 0.4s para 0.06s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função que recebe:\n",
    "    #n = número de resultados à serem obtidos\n",
    "    #dadoz = dataframe limpo (após passar por limparDados)\n",
    "    \n",
    "def loop(n,dadosz):\n",
    "    resultados=[]\n",
    "    \n",
    "    start = time.time()\n",
    "    for j in range(n):\n",
    "        treinoOrigz=dadosz.sample(frac=percentTreino,random_state=randint(0,100000))\n",
    "        testeOrigz=dadosz.drop(treinoOrigz.index)\n",
    "\n",
    "        #Criar índices e preparar teste e treino:\n",
    "        treinoOrigz.index,testeOrigz.index  = range(len(treinoOrigz)), range(len(testeOrigz))\n",
    "        testez, treinoz = testeOrigz.copy(deep=True), treinoOrigz.copy(deep=True)\n",
    "\n",
    "        pA, pB = (len(treinoz[treinoz.Class==nomeA]))/(len(treinoz)), (len(treinoz[treinoz.Class==nomeB]))/(len(treinoz)) \n",
    "        \n",
    "        \n",
    "        ###### FREQUÊNCIAS DAS PALAVRAS ######\n",
    "        freq = {} #Tabela de frequências \n",
    "\n",
    "        #Para reduzirmos o tempo de execução transformamos o dataframe num dicionário\n",
    "        dicionas=treinoz.to_dict()\n",
    "\n",
    "        for numLinha in range(len(dicionas['Email'])): \n",
    "\n",
    "            for palavra in dicionas['Email'][numLinha].split(' '):\n",
    "                if palavra not in freq:\n",
    "                    freq[palavra] = {n_WiA:0,n_WiB:0,p_WcA:0,p_WcB:0}\n",
    "                if dicionas['Class'][numLinha] == nomeA:\n",
    "                    freq[palavra][n_WiA] +=1\n",
    "                else:\n",
    "                    freq[palavra][n_WiB] +=1\n",
    "\n",
    "        #Contagens:       \n",
    "        palavrasA,palavrasB = 0,0\n",
    "        for key,valor in freq.items():  \n",
    "            palavrasA += valor[n_WiA]\n",
    "            palavrasB += valor[n_WiB]\n",
    "\n",
    "        for palavra,valor in freq.items():   \n",
    "            freq[palavra][p_WcA] = (valor[n_WiA]+1)/(palavrasA+len(freq)) #Laplace Smoothing\n",
    "            freq[palavra][p_WcB] = (valor[n_WiB]+1)/(palavrasB+len(freq)) #len(freq) = Nº palavras distintas\n",
    "\n",
    "\n",
    "        ###### CLASSIFICADOR ######\n",
    "        mensagens={}\n",
    "        lTesteOClass = list(testeOrigz.loc[:,'Class'])\n",
    "        lTesteCEmail = list(testez.loc[:,'Email'])\n",
    "        \n",
    "        for numLinha in range(len(testez)):   \n",
    "            mensagens[numLinha] = {'Classe original':lTesteOClass[numLinha],p_AcT:0,p_BcT:0}\n",
    "\n",
    "            pAcT,pBcT=1,1\n",
    "            for palavra in lTesteCEmail[numLinha].split(' '):    \n",
    "                if palavra in freq.keys():\n",
    "                    pAcT*= freq[palavra][p_WcA] \n",
    "                    pBcT*= freq[palavra][p_WcB] \n",
    "                else:\n",
    "                    pAcT*= 1/(palavrasA +len(freq))\n",
    "                    pBcT*= 1/(palavrasB + len(freq))\n",
    "\n",
    "            mensagens[numLinha][p_AcT] = pAcT*pA\n",
    "            mensagens[numLinha][p_BcT] = pBcT*pB\n",
    "\n",
    "            if pAcT >= pBcT:\n",
    "                mensagens[numLinha]['Classe calculada'] = nomeA\n",
    "            if pAcT < pBcT: \n",
    "                mensagens[numLinha]['Classe calculada'] = nomeB\n",
    "\n",
    "        acertos = 0 \n",
    "        for k in range(len(mensagens)):\n",
    "            if mensagens[k]['Classe original'] == mensagens[k]['Classe calculada']:\n",
    "                acertos+=1\n",
    "\n",
    "        resultados.append(round(100*acertos/len(mensagens),3))\n",
    "        j+=1\n",
    "    end = time.time()\n",
    "    print(\"Tempo médio por iteração:\",round(1000*(end-start)/n,4),'ms  | Tempo total:',(end-start),'s')\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo médio por iteração: 36.2393 ms  | Tempo total: 362.39269161224365 s\n"
     ]
    }
   ],
   "source": [
    "repeticoes = 10000\n",
    "passa = loop(repeticoes,dadosL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Histograma dos 10 mil resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x291e2469630>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sResult= pd.Series(data=passa)\n",
    "sResult.plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtemos uma distribuição semelhante a uma distribuição normal simétrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10000.000000\n",
       "mean        95.813637\n",
       "std          0.488336\n",
       "min         93.754000\n",
       "25%         95.477000\n",
       "50%         95.836000\n",
       "75%         96.123000\n",
       "max         97.775000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sResult.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
